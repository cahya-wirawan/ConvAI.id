{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvAI-ID.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1a3G3btJmXlNqUJkTMykXWg9nuuwnRPY2",
      "authorship_tag": "ABX9TyMjjj0tWnLmMYHa+CCAkJ5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cahya-wirawan/ConvAI.id/blob/main/ConvAI_ID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open Domain Chatbot with Indonesian GPT-2"
      ],
      "metadata": {
        "id": "CJkSs7T0YKj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCdIb0skUGx8",
        "outputId": "cf2b80a7-f331-46c1-e5ab-bbd5fbc99492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 19 22:16:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of Huggingface's Transformers and Facebook's ParlAI\n",
        "We need to install Transformers and ParlAI to be able to finetune GPT-2 with dialog datasets. We have to install the latest version of ParlAI from its repository, since the support for arbitrary GPT-2 models has been just added few days ago (18. Feb. 2022) https://github.com/facebookresearch/ParlAI/pull/4360\n"
      ],
      "metadata": {
        "id": "-XE206qqYoXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install transformers\n",
        "!python -m pip install git+https://github.com/facebookresearch/ParlAI.git"
      ],
      "metadata": {
        "id": "pEKxCWHLdhTu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import parlai\n",
        "parlai.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tZLhvvwrUmuu",
        "outputId": "926e55dd-9f6f-4962-f589-8dfcf21e7da5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.5.1'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Indonesian ConvAI2 and Empathetic Dialog Dataset\n",
        "Currently we have two indonesian dialog dataset, translated from the english ConvAI2 (Persona Chat) and Empathetic Dialogues dataset. For this demo, we will only fine tune the empathetic dialog dataset. We download and store it in the directory \"/content/data\""
      ],
      "metadata": {
        "id": "MDSw6hG9WsNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data\n",
        "# !cd data && wget https://cloud.uncool.ai/index.php/s/Sr66KMPeAs85Si4/download/ConvAI.tgz\n",
        "# !cd data && tar xvzf ConvAI.tgz\n",
        "!cd data && wget https://cloud.uncool.ai/index.php/s/kCg6QZoZqNgxoww/download/empatheticdialogues.tgz\n",
        "!cd data && tar xvzf empatheticdialogues.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydnuokZdldOH",
        "outputId": "78506a81-93f3-44b8-b941-1b08a865bb6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 22:18:52--  https://cloud.uncool.ai/index.php/s/kCg6QZoZqNgxoww/download/empatheticdialogues.tgz\n",
            "Resolving cloud.uncool.ai (cloud.uncool.ai)... 144.76.103.67\n",
            "Connecting to cloud.uncool.ai (cloud.uncool.ai)|144.76.103.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27380436 (26M) [application/x-compressed]\n",
            "Saving to: ‘empatheticdialogues.tgz’\n",
            "\n",
            "empatheticdialogues 100%[===================>]  26.11M  6.55MB/s    in 4.0s    \n",
            "\n",
            "2022-02-19 22:18:57 (6.55 MB/s) - ‘empatheticdialogues.tgz’ saved [27380436/27380436]\n",
            "\n",
            "empatheticdialogues/\n",
            "empatheticdialogues/empatheticdialogues/\n",
            "empatheticdialogues/empatheticdialogues/train.csv\n",
            "empatheticdialogues/empatheticdialogues/valid.csv\n",
            "empatheticdialogues/empatheticdialogues/test.csv\n",
            "empatheticdialogues/.built\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head data/empatheticdialogues/empatheticdialogues/train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bytxdlh1df1d",
        "outputId": "d4a3f2ab-fa73-4f1d-caaa-6448dd52965a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_id,utterance_idx,context,prompt,speaker_idx,utterance,selfeval,tags\n",
            "hit:0_conv:1,1,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,1,Saya ingat akan melihat kembang api bersama sahabat saya. Ini adalah pertama kalinya kami menghabiskan waktu sendirian bersama. Meskipun ada banyak orang_comma_ kami merasa seperti satu-satunya orang di dunia.,5|5|5_2|2|5,\n",
            "hit:0_conv:1,2,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,0,Apakah ini teman yang Anda cintai_comma_ atau hanya sahabat?,5|5|5_2|2|5,\n",
            "hit:0_conv:1,3,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,1,Ini adalah sahabat. Aku merindukannya.,5|5|5_2|2|5,\n",
            "hit:0_conv:1,4,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,0,Kemana dia pergi?,5|5|5_2|2|5,\n",
            "hit:0_conv:1,5,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,1,Kami tidak lagi berbicara.,5|5|5_2|2|5,\n",
            "hit:0_conv:1,6,sentimental,Saya ingat pergi ke kembang api dengan sahabat saya. Ada banyak orang_comma_ tapi rasanya seperti kita di dunia.,0,Oh_comma_ apakah ini sesuatu yang terjadi karena pertengkaran?,5|5|5_2|2|5,\n",
            "hit:1_conv:2,1,takut,saya biasa menakut-nakuti kegelapan,2,rasanya seperti menabrak dinding kosong saat saya melihat kegelapan,4|3|4_3|5|5,\n",
            "hit:1_conv:2,2,takut,saya biasa menakut-nakuti kegelapan,3,Oh ya? Saya tidak benar-benar mengerti caranya,4|3|4_3|5|5,\n",
            "hit:1_conv:2,3,takut,saya biasa menakut-nakuti kegelapan,2,tidakkah kamu merasa begitu.. sungguh menakjubkan,4|3|4_3|5|5,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Datasets Content\n",
        "We can check the content of the dataset using the command line\n",
        "`parlai display_data -t empathetic_dialogues --datapath data`\n",
        "or inside the jupyter or a script. This is also valid for other commands such as training and evaluation."
      ],
      "metadata": {
        "id": "1BALGFVrbEw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.display_data import DisplayData\n",
        "DisplayData.main(\n",
        "  task='empathetic_dialogues',\n",
        "  datapath='data',\n",
        "  num_examples=10\n",
        ")\n",
        "# This is exactly the same as the following command line:\n",
        "# parlai display_data -t empathetic_dialogues --datapath data --num-examples 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79g2PRbg164z",
        "outputId": "543a2583-a63c-4df3-a680-1be46e6433c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:06:04 | Opt:\n",
            "00:06:04 |     allow_missing_init_opts: False\n",
            "00:06:04 |     batchsize: 1\n",
            "00:06:04 |     datapath: data\n",
            "00:06:04 |     datatype: train:ordered\n",
            "00:06:04 |     dict_class: None\n",
            "00:06:04 |     display_add_fields: \n",
            "00:06:04 |     download_path: None\n",
            "00:06:04 |     dynamic_batching: None\n",
            "00:06:04 |     hide_labels: False\n",
            "00:06:04 |     ignore_agent_reply: True\n",
            "00:06:04 |     image_cropsize: 224\n",
            "00:06:04 |     image_mode: raw\n",
            "00:06:04 |     image_size: 256\n",
            "00:06:04 |     init_model: None\n",
            "00:06:04 |     init_opt: None\n",
            "00:06:04 |     is_debug: False\n",
            "00:06:04 |     loglevel: info\n",
            "00:06:04 |     max_display_len: 1000\n",
            "00:06:04 |     model: None\n",
            "00:06:04 |     model_file: None\n",
            "00:06:04 |     multitask_weights: [1]\n",
            "00:06:04 |     mutators: None\n",
            "00:06:04 |     num_examples: 2\n",
            "00:06:04 |     override: \"{'task': 'empathetic_dialogues', 'datapath': 'data', 'num_examples': 2}\"\n",
            "00:06:04 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:06:04 |     remove_political_convos: False\n",
            "00:06:04 |     starttime: Feb20_00-06\n",
            "00:06:04 |     task: empathetic_dialogues\n",
            "00:06:04 |     train_experiencer_only: False\n",
            "00:06:04 |     verbose: False\n",
            "00:06:05 | creating task(s): empathetic_dialogues\n",
            "[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train:ordered\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n",
            "\u001b[0mSaya ingat akan melihat kembang api bersama sahabat saya. Ini adalah pertama kalinya kami menghabiskan waktu sendirian bersama. Meskipun ada banyak orang, kami merasa seperti satu-satunya orang di dunia.\u001b[0;0m\n",
            "   \u001b[1;94mApakah ini teman yang Anda cintai, atau hanya sahabat?\u001b[0;0m\n",
            "\u001b[0mIni adalah sahabat. Aku merindukannya.\u001b[0;0m\n",
            "   \u001b[1;94mKemana dia pergi?\u001b[0;0m\n",
            "00:06:05 | loaded 39057 episodes with a total of 64636 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !parlai display_data -t convai2 --datapath data\n",
        "# !parlai display_data -t empathetic_dialogues --datapath data\n"
      ],
      "metadata": {
        "id": "7uuOdrm8mmOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.train_model import TrainModel\n",
        "TrainModel.main(\n",
        "    task='empathetic_dialogues',\n",
        "    datapath='data',\n",
        "    model='hugging_face/gpt2',\n",
        "    # 'indonesian-nlp/gpt2' is the indonesian GPT-2 small model\n",
        "    model_name='indonesian-nlp/gpt2',\n",
        "    model_file='models/empathetic_dialogues_small',\n",
        "    # model_name='indonesian-nlp/gpt2-medium-indonesian',\n",
        "    # model_file='models/empathetic_dialogues_medium',\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    # use a small learning rate with ADAM optimizer\n",
        "    lr=1e-3,\n",
        "    optimizer='adam',\n",
        "    # optimizer='adafactor'\n",
        "    # warmup_updates=100,\n",
        "    # early stopping on perplexity\n",
        "    validation_metric='ppl',\n",
        "    # train at most 10 minutes, and validate every 0.25 epochs\n",
        "    # max_train_time=120,\n",
        "    num_epochs=1,\n",
        "    validation_every_n_epochs=0.25,\n",
        "    \n",
        "    # depend on your gpu. If you have a V100, this is good\n",
        "    batchsize=2, fp16=True,\n",
        "    #fp16_impl='mem_efficient',\n",
        "    \n",
        "    # speeds up validation\n",
        "    # skip_generation=True,\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        ")"
      ],
      "metadata": {
        "id": "uURl_F8SX1T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download GPT-2 Medium Model finetuned on ConvAI2 and Empathetic Dialog datasets"
      ],
      "metadata": {
        "id": "76kdX-1Ud86l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "# !mkdir -p models\n",
        "# !cd models && wget https://cdn-lfs.huggingface.co/cahya/persona_empathetic/05de188749c3ab1ae93978044116c4acc3b31efb9bc3b769a18f11219830db18 -O persona_empathetic.tar\n",
        "# !cd models && tar xvf persona_empathetic.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ejKVO9gM5T8",
        "outputId": "b3368288-3c7c-469b-8a56-c5ebbf876a87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 23:08:06--  https://cdn-lfs.huggingface.co/cahya/persona_empathetic/05de188749c3ab1ae93978044116c4acc3b31efb9bc3b769a18f11219830db18\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.224.154.93, 13.224.154.121, 13.224.154.37, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.224.154.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5703321600 (5.3G) [binary/octet-stream]\n",
            "Saving to: ‘persona_empathetic.tar’\n",
            "\n",
            "persona_empathetic. 100%[===================>]   5.31G  13.9MB/s    in 4m 11s  \n",
            "\n",
            "2022-02-19 23:12:19 (21.6 MB/s) - ‘persona_empathetic.tar’ saved [5703321600/5703321600]\n",
            "\n",
            "persona_empathetic/\n",
            "persona_empathetic/medium.trainstats\n",
            "persona_empathetic/medium\n",
            "persona_empathetic/medium.dict\n",
            "persona_empathetic/medium.dict.opt\n",
            "persona_empathetic/medium.opt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='empathetic_dialogues',\n",
        "    datapath='data',\n",
        "    model_file='models/empathetic_dialogues_small',\n",
        "    # model_file='models/persona_empathetic/medium',\n",
        "    num_examples=15,\n",
        "    skip_generation=False,\n",
        "    inference='beam',\n",
        "    beam_size=10,\n",
        "    beam_context_block_ngram=3,\n",
        "    beam_block_ngram=3,\n",
        "    beam_min_length=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nibvawHleRm3",
        "outputId": "22d29fd5-28da-4ee0-e709-4fc28e8c66ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:27:23 | \u001b[33mOverriding opt[\"inference\"] to beam (previously: greedy)\u001b[0m\n",
            "00:27:23 | \u001b[33mOverriding opt[\"beam_size\"] to 10 (previously: 1)\u001b[0m\n",
            "00:27:23 | \u001b[33mOverriding opt[\"beam_context_block_ngram\"] to 3 (previously: -1)\u001b[0m\n",
            "00:27:23 | \u001b[33mOverriding opt[\"beam_block_ngram\"] to 3 (previously: -1)\u001b[0m\n",
            "00:27:23 | \u001b[33mOverriding opt[\"beam_min_length\"] to 15 (previously: 1)\u001b[0m\n",
            "00:27:23 | Using CUDA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at indonesian-nlp/gpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:27:33 | Total parameters: 124,441,344 (124,441,344 trainable)\n",
            "00:27:33 | Loading existing model params from models/empathetic_dialogues_small\n",
            "00:27:35 | creating task(s): empathetic_dialogues\n",
            "[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n",
            "00:27:35 | Opt:\n",
            "00:27:35 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "00:27:35 |     adam_eps: 1e-08\n",
            "00:27:35 |     add_p1_after_newln: False\n",
            "00:27:35 |     add_special_tokens: True\n",
            "00:27:35 |     add_start_token: False\n",
            "00:27:35 |     aggregate_micro: False\n",
            "00:27:35 |     allow_missing_init_opts: False\n",
            "00:27:35 |     batchsize: 2\n",
            "00:27:35 |     beam_block_full_context: True\n",
            "00:27:35 |     beam_block_list_filename: None\n",
            "00:27:35 |     beam_block_ngram: 3\n",
            "00:27:35 |     beam_context_block_ngram: 3\n",
            "00:27:35 |     beam_delay: 30\n",
            "00:27:35 |     beam_length_penalty: 0.65\n",
            "00:27:35 |     beam_min_length: 15\n",
            "00:27:35 |     beam_size: 10\n",
            "00:27:35 |     betas: '[0.9, 0.999]'\n",
            "00:27:35 |     bpe_add_prefix_space: None\n",
            "00:27:35 |     bpe_debug: False\n",
            "00:27:35 |     bpe_dropout: None\n",
            "00:27:35 |     bpe_merge: None\n",
            "00:27:35 |     bpe_vocab: None\n",
            "00:27:35 |     compute_tokenized_bleu: False\n",
            "00:27:35 |     datapath: data\n",
            "00:27:35 |     datatype: train\n",
            "00:27:35 |     delimiter: '\\n'\n",
            "00:27:35 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "00:27:35 |     dict_endtoken: __end__\n",
            "00:27:35 |     dict_file: models/empathetic_dialogues_small.dict\n",
            "00:27:35 |     dict_include_test: False\n",
            "00:27:35 |     dict_include_valid: False\n",
            "00:27:35 |     dict_initpath: None\n",
            "00:27:35 |     dict_language: english\n",
            "00:27:35 |     dict_lower: False\n",
            "00:27:35 |     dict_max_ngram_size: -1\n",
            "00:27:35 |     dict_maxexs: 0\n",
            "00:27:35 |     dict_maxtokens: -1\n",
            "00:27:35 |     dict_minfreq: 0\n",
            "00:27:35 |     dict_nulltoken: __null__\n",
            "00:27:35 |     dict_starttoken: __start__\n",
            "00:27:35 |     dict_textfields: text,labels\n",
            "00:27:35 |     dict_tokenizer: re\n",
            "00:27:35 |     dict_unktoken: __unk__\n",
            "00:27:35 |     display_add_fields: \n",
            "00:27:35 |     display_examples: False\n",
            "00:27:35 |     download_path: None\n",
            "00:27:35 |     dynamic_batching: full\n",
            "00:27:35 |     embedding_projection: random\n",
            "00:27:35 |     embedding_type: random\n",
            "00:27:35 |     eval_batchsize: None\n",
            "00:27:35 |     eval_dynamic_batching: None\n",
            "00:27:35 |     evaltask: None\n",
            "00:27:35 |     final_extra_opt: \n",
            "00:27:35 |     force_fp16_tokens: True\n",
            "00:27:35 |     fp16: True\n",
            "00:27:35 |     fp16_impl: safe\n",
            "00:27:36 |     gpt2_size: small\n",
            "00:27:36 |     gpu: -1\n",
            "00:27:36 |     gradient_clip: 0.1\n",
            "00:27:36 |     hide_labels: False\n",
            "00:27:36 |     history_add_global_end_token: None\n",
            "00:27:36 |     history_reversed: False\n",
            "00:27:36 |     history_size: -1\n",
            "00:27:36 |     image_cropsize: 224\n",
            "00:27:36 |     image_mode: raw\n",
            "00:27:36 |     image_size: 256\n",
            "00:27:36 |     inference: beam\n",
            "00:27:36 |     init_model: None\n",
            "00:27:36 |     init_opt: None\n",
            "00:27:36 |     interactive_mode: False\n",
            "00:27:36 |     invsqrt_lr_decay_gamma: -1\n",
            "00:27:36 |     is_debug: False\n",
            "00:27:36 |     label_truncate: 256\n",
            "00:27:36 |     learningrate: 0.001\n",
            "00:27:36 |     log_every_n_secs: -1\n",
            "00:27:36 |     log_every_n_steps: 50\n",
            "00:27:36 |     loglevel: info\n",
            "00:27:36 |     lr_scheduler: reduceonplateau\n",
            "00:27:36 |     lr_scheduler_decay: 0.5\n",
            "00:27:36 |     lr_scheduler_patience: 3\n",
            "00:27:36 |     max_train_steps: -1\n",
            "00:27:36 |     max_train_time: 120.0\n",
            "00:27:36 |     metrics: default\n",
            "00:27:36 |     model: hugging_face/gpt2\n",
            "00:27:36 |     model_file: models/empathetic_dialogues_small\n",
            "00:27:36 |     model_name: indonesian-nlp/gpt2\n",
            "00:27:36 |     momentum: 0\n",
            "00:27:36 |     multitask_weights: [1]\n",
            "00:27:36 |     mutators: None\n",
            "00:27:36 |     nesterov: True\n",
            "00:27:36 |     no_cuda: False\n",
            "00:27:36 |     num_epochs: -1\n",
            "00:27:36 |     num_examples: 15\n",
            "00:27:36 |     num_workers: 0\n",
            "00:27:36 |     nus: [0.7]\n",
            "00:27:36 |     optimizer: adam\n",
            "00:27:36 |     override: \"{'task': 'empathetic_dialogues', 'datapath': 'data', 'model_file': 'models/empathetic_dialogues_small', 'num_examples': '15', 'skip_generation': False, 'inference': 'beam', 'beam_size': 10, 'beam_context_block_ngram': 3, 'beam_block_ngram': 3, 'beam_min_length': 15}\"\n",
            "00:27:36 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:27:36 |     person_tokens: False\n",
            "00:27:36 |     rank_candidates: False\n",
            "00:27:36 |     remove_political_convos: False\n",
            "00:27:36 |     save_after_valid: False\n",
            "00:27:36 |     save_every_n_secs: -1\n",
            "00:27:36 |     short_final_eval: False\n",
            "00:27:36 |     skip_generation: False\n",
            "00:27:36 |     special_tok_lst: None\n",
            "00:27:36 |     split_lines: False\n",
            "00:27:36 |     starttime: Feb20_00-13\n",
            "00:27:36 |     task: empathetic_dialogues\n",
            "00:27:36 |     temperature: 1.0\n",
            "00:27:36 |     tensorboard_log: False\n",
            "00:27:36 |     tensorboard_logdir: None\n",
            "00:27:36 |     text_truncate: 768\n",
            "00:27:36 |     topk: 10\n",
            "00:27:36 |     topp: 0.9\n",
            "00:27:36 |     train_experiencer_only: False\n",
            "00:27:36 |     truncate: -1\n",
            "00:27:36 |     update_freq: 1\n",
            "00:27:36 |     use_reply: label\n",
            "00:27:36 |     validation_cutoff: 1.0\n",
            "00:27:36 |     validation_every_n_epochs: 0.25\n",
            "00:27:36 |     validation_every_n_secs: -1\n",
            "00:27:36 |     validation_every_n_steps: -1\n",
            "00:27:36 |     validation_max_exs: -1\n",
            "00:27:36 |     validation_metric: ppl\n",
            "00:27:36 |     validation_metric_mode: None\n",
            "00:27:36 |     validation_patience: 10\n",
            "00:27:36 |     validation_share_agent: False\n",
            "00:27:36 |     verbose: False\n",
            "00:27:36 |     wandb_entity: None\n",
            "00:27:36 |     wandb_log: False\n",
            "00:27:36 |     wandb_name: None\n",
            "00:27:36 |     wandb_project: None\n",
            "00:27:36 |     warmup_rate: 0.0001\n",
            "00:27:36 |     warmup_updates: -1\n",
            "00:27:36 |     weight_decay: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py:1749: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  hyp_ids = best_idxs // voc_size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mHari ini, saat saya berangkat kerja di pagi hari, ban saya pecah di tengah jalan yang sibuk. Itu membuatku takut!\u001b[0;0m\n",
            "\u001b[1;94m    labels: Apakah kamu baik-baik saja sekarang?\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh tidak! Saya harap semuanya berjalan dengan baik untuk Anda. Saya harap Anda baik-baik saja!\u001b[0;0m\n",
            "\u001b[0mYa, saya baik-baik saja sekarang, tetapi dengan luka ringan.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Keren :) Apakah mobil Anda banyak rusak?\u001b[0;0m\n",
            "\u001b[0;95m     model: Saya harap semuanya berjalan dengan baik untuk Anda. Saya harap Anda merasa lebih baik.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mBeberapa minggu yang lalu, saya sedang berjalan melalui lorong saya, mengurus urusan saya sendiri, ketika tiba-tiba sebuah tangan mengulurkan tangan dari bawah meja dan meraih pergelangan kaki saya. Saya sangat terharu. Saya pikir saya didapat. Ternyata, itu anak saya.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Itu lucu, semoga dia tidak memberimu serangan jantung.\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh tidak! Itu mengerikan. Saya harap semuanya berjalan dengan baik pada akhirnya.\u001b[0;0m\n",
            "\u001b[0mSaya mungkin telah mengeluarkan jeritan yang akan membuatnya mempertanyakan kejantanan saya selama sisa hidup kita, lol.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Saya mungkin akan berteriak juga.\u001b[0;0m\n",
            "\u001b[0;95m     model: Saya harap begitu juga. Saya harap dia tidak melukai diri sendiri dengan itu.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mSaya terlalu bersemangat karena akan terbang ke luar negeri untuk pertama kalinya besok. \". Silakan masuk ke sini...\u001b[0;0m\n",
            "\u001b[1;94m    labels: Wow! Kedengarannya luar biasa. Kemana kamu pergi?\u001b[0;0m\n",
            "\u001b[0;95m     model: Saya harap semuanya berjalan dengan baik untuk Anda! Saya harap Anda bersenang-senang!\u001b[0;0m\n",
            "\u001b[0mBepergian ke Afrika Selatan lalu ke Ghana. Juga pertama kali saya mengunjungi Afrika\u001b[0;0m\n",
            "\u001b[1;94m    labels: Saya yakin Anda akan menyukainya. Perjalanan Aman!\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh, itu luar biasa! Saya harap Anda bersenang-senang di sana.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mSuatu kali, saya menggendong anak saya di atas kepala saya, ketika tiba-tiba, dia mengangkat seluruh wajah saya. Saya hampir menangis.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Itu mengerikan, semoga dia baik-baik saja.\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh tidak! Itu mengerikan. Saya harap semuanya berjalan dengan baik pada akhirnya.\u001b[0;0m\n",
            "\u001b[0mya, dia baru saja minum botol, dan saya memindahkannya seperti pesawat terbang. Dalam retrospeksi. Saya pantas mendapatkannya.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Begitu, senang dia baik-baik saja.\u001b[0;0m\n",
            "\u001b[0;95m     model: Saya harap semuanya berjalan dengan baik untuknya. Saya yakin dia akan merasa lebih baik.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mHalo\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hai apa kabar?\u001b[0;0m\n",
            "\u001b[0;95m     model: ya, saya tidak sabar untuk melihat apa yang akan saya lakukan dengan itu.\u001b[0;0m\n",
            "\u001b[0mSaya baik-baik saja, saya hanya ingin menceritakan sebuah cerita pendek tentang saat saya membantu seorang wanita tua. Dia berjuang untuk membawa tasnya dari perjalanan yang dia lakukan. Saya membantunya membawanya ke pintunya! Perasaan yang cukup bagus saat Anda membantu orang lain\u001b[0;0m\n",
            "\u001b[1;94m    labels: Anda seperti itu, saya yakin mereka menghargai itu!\u001b[0;0m\n",
            "\u001b[0;95m     model: Itu luar biasa! Saya senang Anda melakukannya dengan baik. Saya harap semuanya berjalan dengan baik untuk Anda.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mSaya pergi ke trotoar Kemah dengan pacar saya. Itu membuat saya memikirkan saat-saat saya pergi berlibur bersama keluarga saya.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Liburan terakhir saya berjalan sangat salahQ!\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh tidak! Saya harap semuanya berjalan dengan baik untuk Anda dan keluarga Anda!\u001b[0;0m\n",
            "\u001b[0mYang saya pikirkan hanyalah berada di rumah lagi dan bisa menghidupkan kembali momen-momen itu.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Ya, saya suka mengingatkan\u001b[0;0m\n",
            "\u001b[0;95m     model:  Saya harap semuanya berjalan dengan baikTerima kasih! Saya harap Anda bisa menghidupkan kenangan indah itu.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mAnjing saya mati beberapa tahun yang lalu setelah saya memiliki anak laki-laki saya. Itu tepat sekitar Natal dan saya memiliki anjing itu selama empat belas tahun.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Saya menyesal mendengarnya. Saya tidak pernah punya anjing. Apa pengalamanmu tentang anjing itu?\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh tidak! Saya sangat menyesal mendengarnya. Saya harap semuanya berjalan dengan baik pada akhirnya.\u001b[0;0m\n",
            "\u001b[0mAnjing itu ada di sana sepanjang hidup saya. Dia melihat saya melalui pacar dan teman.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Saya sangat menyesal mendengarnya. Siapa nama anjingnya?\u001b[0;0m\n",
            "\u001b[0;95m     model: Oh, itu sangat menyedihkan. Saya harap semuanya berjalan dengan baik untuk Anda.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mHalo\u001b[0;0m\n",
            "\u001b[1;94m    labels: Halo Bagaimana kabarmu dan apa obrolan ceritamu hari ini?\u001b[0;0m\n",
            "\u001b[0;95m     model: ya, saya tidak sabar untuk melihat apa yang akan saya lakukan dengan itu.\u001b[0;0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Interactive script\n",
        "from parlai.scripts.interactive import Interactive\n",
        "\n",
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # model_file='models/empathetic_dialogues_small',\n",
        "    model_file='models/persona_empathetic/medium',\n",
        "    inference='beam',\n",
        "    beam_size=10,\n",
        "    beam_context_block_ngram=3,\n",
        "    beam_block_ngram=3,\n",
        "    beam_min_length=15\n",
        ")"
      ],
      "metadata": {
        "id": "ZkF1eZnsiag_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai interactive --model \"hugging_face/gpt2\" -mf \"models/persona_empathetic/medium\" --inference beam --beam-size 10 --beam-context-block-ngram 3 --beam-block-ngram 3 --beam-min-length 25 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZHnMGdtiA2Q",
        "outputId": "caf00cab-2e7d-4a08-d1c8-2c8f8ea562a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "00:39:17 | \u001b[33mWARNING: this model is in beta and the API is subject to change.\u001b[0m\n",
            "00:39:17 | \u001b[33mOverriding opt[\"inference\"] to beam (previously: greedy)\u001b[0m\n",
            "00:39:17 | \u001b[33mOverriding opt[\"beam_size\"] to 10 (previously: 1)\u001b[0m\n",
            "00:39:17 | \u001b[33mOverriding opt[\"beam_context_block_ngram\"] to 3 (previously: -1)\u001b[0m\n",
            "00:39:17 | \u001b[33mOverriding opt[\"beam_block_ngram\"] to 3 (previously: -1)\u001b[0m\n",
            "00:39:17 | \u001b[33mOverriding opt[\"beam_min_length\"] to 25 (previously: 1)\u001b[0m\n",
            "00:39:17 | Using CUDA\n",
            "00:39:22 | Gpt2: full interactive mode on.\n",
            "Some weights of the model checkpoint at flax-community/gpt2-medium-indonesian were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "00:39:35 | Total parameters: 354,825,216 (354,825,216 trainable)\n",
            "00:39:35 | Loading existing model params from models/persona_empathetic/medium\n",
            "00:39:40 | Opt:\n",
            "00:39:40 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "00:39:40 |     adam_eps: 1e-08\n",
            "00:39:40 |     add_p1_after_newln: False\n",
            "00:39:40 |     add_special_tokens: True\n",
            "00:39:40 |     add_start_token: True\n",
            "00:39:40 |     aggregate_micro: False\n",
            "00:39:40 |     allow_missing_init_opts: False\n",
            "00:39:40 |     batchsize: 2\n",
            "00:39:40 |     beam_block_full_context: True\n",
            "00:39:40 |     beam_block_list_filename: None\n",
            "00:39:40 |     beam_block_ngram: 3\n",
            "00:39:40 |     beam_context_block_ngram: 3\n",
            "00:39:40 |     beam_delay: 30\n",
            "00:39:40 |     beam_length_penalty: 0.65\n",
            "00:39:40 |     beam_min_length: 25\n",
            "00:39:40 |     beam_size: 10\n",
            "00:39:40 |     betas: '[0.9, 0.999]'\n",
            "00:39:40 |     bpe_add_prefix_space: None\n",
            "00:39:40 |     bpe_debug: False\n",
            "00:39:40 |     bpe_dropout: None\n",
            "00:39:40 |     bpe_merge: None\n",
            "00:39:40 |     bpe_vocab: None\n",
            "00:39:40 |     compute_tokenized_bleu: False\n",
            "00:39:40 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:39:40 |     datatype: train\n",
            "00:39:40 |     ddp_backend: ddp\n",
            "00:39:40 |     delimiter: '\\n'\n",
            "00:39:40 |     dict_class: parlai.agents.hugging_face.dict:Gpt2DictionaryAgent\n",
            "00:39:40 |     dict_endtoken: __end__\n",
            "00:39:40 |     dict_file: models/persona_empathetic/medium.dict\n",
            "00:39:40 |     dict_include_test: False\n",
            "00:39:40 |     dict_include_valid: False\n",
            "00:39:40 |     dict_initpath: None\n",
            "00:39:40 |     dict_language: english\n",
            "00:39:40 |     dict_lower: False\n",
            "00:39:40 |     dict_max_ngram_size: -1\n",
            "00:39:40 |     dict_maxexs: 0\n",
            "00:39:40 |     dict_maxtokens: -1\n",
            "00:39:40 |     dict_minfreq: 0\n",
            "00:39:40 |     dict_nulltoken: __null__\n",
            "00:39:40 |     dict_starttoken: __start__\n",
            "00:39:40 |     dict_textfields: text,labels\n",
            "00:39:40 |     dict_tokenizer: re\n",
            "00:39:40 |     dict_unktoken: __unk__\n",
            "00:39:40 |     display_add_fields: \n",
            "00:39:40 |     display_examples: False\n",
            "00:39:40 |     display_prettify: False\n",
            "00:39:40 |     distributed_world_size: 8\n",
            "00:39:40 |     download_path: None\n",
            "00:39:40 |     dynamic_batching: full\n",
            "00:39:40 |     embedding_projection: random\n",
            "00:39:40 |     embedding_type: random\n",
            "00:39:40 |     eval_batchsize: None\n",
            "00:39:40 |     eval_dynamic_batching: None\n",
            "00:39:40 |     evaltask: None\n",
            "00:39:40 |     final_extra_opt: \n",
            "00:39:40 |     force_fp16_tokens: False\n",
            "00:39:40 |     fp16: False\n",
            "00:39:40 |     fp16_impl: safe\n",
            "00:39:40 |     gpt2_size: small\n",
            "00:39:40 |     gpu: 0\n",
            "00:39:40 |     gradient_clip: 0.1\n",
            "00:39:40 |     hide_labels: False\n",
            "00:39:40 |     history_add_global_end_token: None\n",
            "00:39:40 |     history_reversed: False\n",
            "00:39:40 |     history_size: -1\n",
            "00:39:40 |     image_cropsize: 224\n",
            "00:39:40 |     image_mode: raw\n",
            "00:39:40 |     image_size: 256\n",
            "00:39:40 |     inference: beam\n",
            "00:39:40 |     init_model: None\n",
            "00:39:40 |     init_opt: None\n",
            "00:39:40 |     interactive_mode: True\n",
            "00:39:40 |     interactive_task: True\n",
            "00:39:40 |     invsqrt_lr_decay_gamma: -1\n",
            "00:39:40 |     is_debug: False\n",
            "00:39:40 |     label_truncate: 256\n",
            "00:39:40 |     learningrate: 0.0005\n",
            "00:39:40 |     local_human_candidates_file: None\n",
            "00:39:40 |     log_every_n_secs: -1\n",
            "00:39:40 |     log_every_n_steps: 50\n",
            "00:39:40 |     log_keep_fields: all\n",
            "00:39:40 |     loglevel: info\n",
            "00:39:40 |     lr_scheduler: reduceonplateau\n",
            "00:39:40 |     lr_scheduler_decay: 0.5\n",
            "00:39:40 |     lr_scheduler_patience: 3\n",
            "00:39:40 |     max_train_steps: -1\n",
            "00:39:40 |     max_train_time: -1\n",
            "00:39:40 |     metrics: default\n",
            "00:39:40 |     model: hugging_face/gpt2\n",
            "00:39:40 |     model_file: models/persona_empathetic/medium\n",
            "00:39:40 |     model_name: flax-community/gpt2-medium-indonesian\n",
            "00:39:40 |     momentum: 0\n",
            "00:39:40 |     multiprocessing: True\n",
            "00:39:40 |     multitask_weights: [1]\n",
            "00:39:40 |     mutators: None\n",
            "00:39:40 |     nesterov: True\n",
            "00:39:40 |     no_cuda: False\n",
            "00:39:40 |     num_epochs: 2.0\n",
            "00:39:40 |     num_workers: 8\n",
            "00:39:40 |     nus: [0.7]\n",
            "00:39:40 |     optimizer: adam\n",
            "00:39:40 |     outfile: \n",
            "00:39:40 |     override: \"{'model': 'hugging_face/gpt2', 'model_file': 'models/persona_empathetic/medium', 'inference': 'beam', 'beam_size': 10, 'beam_context_block_ngram': 3, 'beam_block_ngram': 3, 'beam_min_length': 25}\"\n",
            "00:39:40 |     parlai_home: /root/Work/ParlAI\n",
            "00:39:40 |     person_tokens: False\n",
            "00:39:40 |     port: None\n",
            "00:39:40 |     rank: 0\n",
            "00:39:40 |     rank_candidates: False\n",
            "00:39:40 |     remove_political_convos: False\n",
            "00:39:40 |     save_after_valid: False\n",
            "00:39:40 |     save_every_n_secs: -1\n",
            "00:39:40 |     save_format: conversations\n",
            "00:39:40 |     short_final_eval: False\n",
            "00:39:40 |     single_turn: False\n",
            "00:39:40 |     skip_generation: False\n",
            "00:39:40 |     special_tok_lst: None\n",
            "00:39:40 |     split_lines: False\n",
            "00:39:40 |     starttime: Feb19_18-24\n",
            "00:39:40 |     task: convai2,empathetic_dialogues\n",
            "00:39:40 |     temperature: 1.0\n",
            "00:39:40 |     tensorboard_log: False\n",
            "00:39:40 |     tensorboard_logdir: None\n",
            "00:39:40 |     text_truncate: 768\n",
            "00:39:40 |     topk: 10\n",
            "00:39:40 |     topp: 0.9\n",
            "00:39:40 |     train_experiencer_only: False\n",
            "00:39:40 |     truncate: -1\n",
            "00:39:40 |     update_freq: 1\n",
            "00:39:40 |     use_reply: label\n",
            "00:39:40 |     validation_cutoff: 1.0\n",
            "00:39:40 |     validation_every_n_epochs: -1\n",
            "00:39:40 |     validation_every_n_secs: 500.0\n",
            "00:39:40 |     validation_every_n_steps: -1\n",
            "00:39:40 |     validation_max_exs: -1\n",
            "00:39:40 |     validation_metric: ppl\n",
            "00:39:40 |     validation_metric_mode: None\n",
            "00:39:40 |     validation_patience: 10\n",
            "00:39:40 |     validation_share_agent: False\n",
            "00:39:40 |     verbose: False\n",
            "00:39:40 |     wandb_entity: None\n",
            "00:39:40 |     wandb_log: False\n",
            "00:39:40 |     wandb_name: None\n",
            "00:39:40 |     wandb_project: None\n",
            "00:39:40 |     warmup_rate: 0.0001\n",
            "00:39:40 |     warmup_updates: -1\n",
            "00:39:40 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "00:39:41 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Hi apa kabar\n",
            "/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py:1749: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  hyp_ids = best_idxs // voc_size\n",
            "\u001b[0;34m[Gpt2]:\u001b[0;0m \u001b[1mSaya baik-baik saja. Apakah kamu punya rencana untuk akhir pekan ini? Saya pikir saya akan pergi ke pantai dengan teman-teman.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m tidak. siapa nama kamu\n",
            "/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py:1749: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  hyp_ids = best_idxs // voc_size\n",
            "\u001b[0;34m[Gpt2]:\u001b[0;0m \u001b[1mOscar. Saya harap Anda bersenang-senang di pantai. Saya tidak punya siapa-siapa untuk mengawasi anak-anak.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Kamu punya berapa anak?\n",
            "\u001b[0;34m[Gpt2]:\u001b[0;0m \u001b[1mSaya punya 3 anak laki-laki dan 1 anak perempuan. Saya berharap saya punya lebih banyak waktu untuk mengawasi mereka saat mereka tumbuh dewasa.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Saya ingin sekali punya anak juga, tapi sampai saat ini saya belum mendapatkan istri yang cocok\n",
            "\u001b[0;34m[Gpt2]:\u001b[0;0m \u001b[1mSaya harap Anda menemukan wanita yang tepat untuk Anda. Saya memiliki seorang putra dan seorang putri, tetapi saya belum menemukan yang cocok.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/models /content/drive/MyDrive/ConvAI/"
      ],
      "metadata": {
        "id": "F0gR4rEoycJ8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/ConvAI/models /content"
      ],
      "metadata": {
        "id": "t1oP3QFczHoK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lh /content/drive/MyDrive/ConvAI/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSprVjv19237",
        "outputId": "4f1b3d85-7301-482b-c87b-dbf5af8d0742"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 9.6G\n",
            "-rw------- 1 root root 250M Feb 19 17:17 empathetic_dialogues_01\n",
            "-rw------- 1 root root 506K Feb 19 17:17 empathetic_dialogues_01.dict\n",
            "-rw------- 1 root root 4.4K Feb 19 17:17 empathetic_dialogues_01.dict.opt\n",
            "-rw------- 1 root root 3.8K Feb 19 17:17 empathetic_dialogues_01.opt\n",
            "-rw------- 1 root root  353 Feb 19 17:17 empathetic_dialogues_01.test\n",
            "-rw------- 1 root root  23K Feb 19 17:17 empathetic_dialogues_01.trainstats\n",
            "-rw------- 1 root root  354 Feb 19 17:17 empathetic_dialogues_01.valid\n",
            "-rw------- 1 root root 4.7G Feb 19 17:15 empathetic_dialogues_medium\n",
            "-rw------- 1 root root 506K Feb 19 17:14 empathetic_dialogues_medium.dict\n",
            "-rw------- 1 root root 4.5K Feb 19 17:15 empathetic_dialogues_medium.dict.opt\n",
            "-rw------- 1 root root 4.7G Feb 19 17:16 empathetic_dialogues_medium_en\n",
            "-rw------- 1 root root 506K Feb 19 17:17 empathetic_dialogues_medium_en.dict\n",
            "-rw------- 1 root root 4.5K Feb 19 17:17 empathetic_dialogues_medium_en.dict.opt\n",
            "-rw------- 1 root root 3.9K Feb 19 17:17 empathetic_dialogues_medium_en.opt\n",
            "-rw------- 1 root root  56K Feb 19 17:17 empathetic_dialogues_medium_en.trainstats\n",
            "-rw------- 1 root root 3.9K Feb 19 17:15 empathetic_dialogues_medium.opt\n",
            "-rw------- 1 root root  355 Feb 19 17:15 empathetic_dialogues_medium.test\n",
            "-rw------- 1 root root  41K Feb 19 17:15 empathetic_dialogues_medium.trainstats\n",
            "-rw------- 1 root root  356 Feb 19 17:15 empathetic_dialogues_medium.valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ptI6iT639-ll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}